{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week13_Discussion.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNsswcnlhc3a5vUjQfz+YZV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/homeiraazari/CloudComputingWeeklyDiscussion/blob/master/Week13_Discussion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDhNTTyNLLcv",
        "colab_type": "text"
      },
      "source": [
        "#**What problems does edge-based machine learning solve?**\n",
        "\n",
        "Most companies today store their data in the cloud. This means that data has to travel to a central data center—which is often located thousands of miles away—for model comparison before the concluding insight can be relayed back to the device of origin. This is a critical and even dangerous problem in cases such as fall detection where time is of the essence.\n",
        " \n",
        "The problem of latency is what is driving many companies to move from the cloud to the edge today. “Intelligence on the edge,” Edge AI” or “Edge machine learning” means that, instead of being processed in algorithms located in the cloud, data is processed locally in algorithms stored on a hardware device. This not only enables real-time operations, but it also helps to significantly reduce the power consumption and security vulnerability associated with processing data in the cloud. \n",
        "\n",
        "\n",
        "#**What are the ML frameworks most widely used with edge inference?**\n",
        "\n",
        "Some of the Machine Learning Frameworks that are widely used with edge inference are TensorFlow Lite, PyTorch Mobile, Core ML3, Apache, and the Embedded Learning Library. Each of these frameworks can be utilized on a variety of devices ( Android devices, iOS devices, Linux devices, etc.). Tensorflow Lite was developed by Google and has APIs for languages such as Java, C++, Python, Swift, and Objective C; this framework is used for creating models that are optimized in size and that provide efficiency. PyTorch Mobile was developed by Facebook; this framework deploys models onto platforms. Core ML3 was developed by Apple. Embedded Learning Library was developed by Microsoft, and it has APIs for C++ and Python. This framework is commonly used to deploy Machine Learning models onto small, single-board computers. After these models have been deployed, they are invoked onto edge devices. Apache was developed by; it has APIs for languages such as Python, R, Scala, C++, and many more. Apache is utilized to help improve training models.\n",
        "\n",
        "#**Post a screenshot of a lab where you had difficulty with a concept or learned something.**\n",
        "\n",
        "I did the Classifying Images with Vision and Core ML lab, I really enjoyed doing it. I learned about the concept of “Classifying Images”.\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/46541929/80765177-5e891080-8b10-11ea-96c2-3443d929d40a.png)"
      ]
    }
  ]
}