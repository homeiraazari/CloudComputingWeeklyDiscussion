{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week11_Discussion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/homeiraazari/CloudComputingWeeklyDiscussion/blob/master/Week11_Discussion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUe7NkX77HFE",
        "colab_type": "text"
      },
      "source": [
        "#**What problems does Hadoop Solve?**\n",
        "Hadoop was designed by Google and then developed by Yahool! engineers. The mere goal of Hadoop is to store data and run applications on clusters of commodity hardware. Hadoop utilizes HDFS (Hadoop Distributed File System) and Map Reduce. HDFS allows for the storage of large quantities of data throughout a cluster. MapReduce is used for the implementation of tasks that process the data. Hadoop is designed to deal with Big Data's three Vs: volume, variety, velocity.\n",
        "\n",
        "* Volume - Hadoop was designed to scale out, and it is much more utilizes to grow the system. As we need more storage or computing capacity, all we need to do is add more nodes to the cluster.\n",
        "\n",
        "* Variety - Hadoop allows us to store data in any format, be that structured or unstructured data. This means that we will not need to alter our data to fit any single schema before putting it into Hadoop. \n",
        "\n",
        "* Velocity -  With Hadoop, we can load raw data into the system and then later define how we want to view it. Because of the flexibility of the system, we can avoid many network and processing bottlenecks associated with loading raw data. Since data is always evolving, the system's flexibility makes the incorporation of any changes much easier.\n",
        "\n",
        "Organizations utilize Hadoop for the reasons exemplified above. It helps them with faster processing on large datasets, which saves them time and money tremendously. Large users of Hadoop include well-known companies like Amazon, Facebook, Adobe, and LinkedIn.\n",
        "\n",
        "#**What are the key differences between Hadoop and Spark?**\n",
        "Apache Spark is another big data framework, like Hadoop. However, the two differ in some key ways:\n",
        "\n",
        "In terms of processing approach, Spark uses in-memory data processing, whereas Hadoop reads and writes data from disk.\n",
        "Thus, with regards to processing speed, Spark may be several times (up to 100 times) faster than Hadoop.\n",
        "Additionally, because Spark uses in-memory processing, it may not be able to process larger volumes of data Hadoop can handle, in cases where the dataset is larger than the available RAM. Hadoop MapReduce can process far more massive datasets than Spark.\n",
        "Therefore, if immediate insights are needed on a relatively large dataset, then it is appropriate to use Spark because of its fast or near real-time processing. In contrast, if the business does not require quicker results on a vast dataset, then Hadoop is appropriate.\n",
        "Spark provides Graph Processing because it is built to deliver iterative computations. The GraphX API is Sparkâ€™s graph computational tool.\n",
        "\n",
        "#**Post a screenshot of a lab where you had difficulty with a concept or learned something.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKkMwSbx7HNe",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXgSk7C57HQI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mVNQ8Hx7HSw",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}